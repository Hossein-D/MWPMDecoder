{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack, kron, eye, csc_matrix, block_diag\n",
    "#pip install pymatching --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c572b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repetition_code(n):\n",
    "    \"\"\"\n",
    "    Parity check matrix of a repetition code with length n.\n",
    "    \"\"\"\n",
    "    row_ind, col_ind = zip(*((i, j) for i in range(n) for j in (i, (i+1)%n)))\n",
    "    #print(\"row_ind = \", row_ind)\n",
    "    #print(\"col_ind = \", col_ind)    \n",
    "    data = np.ones(2*n, dtype=np.uint8)\n",
    "    print(csc_matrix((data, (row_ind, col_ind))).toarray())\n",
    "    return csc_matrix((data, (row_ind, col_ind))).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "014e12b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]\n",
      " [0 1 1]\n",
      " [1 0 1]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "a = np.array(repetition_code(3))\n",
    "#np.matmul(a, )\n",
    "ainv = inv(a)\n",
    "synd = [[1],[1],[0]]\n",
    "print(np.matmul(ainv, synd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3f5966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toric_code_x_stabilisers(L):    \n",
    "    \"\"\"\n",
    "    Sparse check matrix for the X stabilisers of a toric code with\n",
    "    lattice size L, constructed as the hypergraph product of\n",
    "    two repetition codes.\n",
    "    \"\"\"    \n",
    "    Hr = repetition_code(L)\n",
    "    H = hstack(\n",
    "            [kron(Hr, eye(Hr.shape[1])), kron(eye(Hr.shape[0]), Hr.T)],\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "    H.data = H.data % 2\n",
    "    H.eliminate_zeros()\n",
    "    print(\"H = \", H.toarray())\n",
    "    return csc_matrix(H)\n",
    "\n",
    "\n",
    "\n",
    "def toric_code_x_logicals(L):\n",
    "    \"\"\"\n",
    "    Sparse binary matrix with each row corresponding to an X logical operator \n",
    "    of a toric code with lattice size L. Constructed from the \n",
    "    homology groups of the repetition codes using the Kunneth \n",
    "    theorem.\n",
    "    \"\"\"\n",
    "    H1 = csc_matrix(([1], ([0],[0])), shape=(1,L), dtype=np.uint8)\n",
    "    H0 = csc_matrix(np.ones((1, L), dtype=np.uint8))\n",
    "    x_logicals = block_diag([kron(H1, H0), kron(H0, H1)])\n",
    "    x_logicals.data = x_logicals.data % 2\n",
    "    x_logicals.eliminate_zeros()\n",
    "    return csc_matrix(x_logicals)\n",
    "\n",
    "\n",
    "\n",
    "def num_decoding_failures_via_physical_frame_changes(H, logicals, error_probability, num_shots):\n",
    "    matching = Matching.from_check_matrix(H, weights=np.log((1-error_probability)/error_probability))\n",
    "    num_errors = 0\n",
    "    for i in range(num_shots):\n",
    "        noise = (np.random.random(H.shape[1]) < error_probability).astype(np.uint8)\n",
    "        syndrome = H@noise % 2\n",
    "        print(\"syndrome = \", syndrome)\n",
    "        prediction = matching.decode(syndrome)\n",
    "        print(\"prediction = \", prediction)\n",
    "        predicted_logicals_flipped = logicals@prediction % 2\n",
    "        actual_logicals_flipped = logicals@noise % 2\n",
    "        if not np.array_equal(predicted_logicals_flipped, actual_logicals_flipped):\n",
    "            num_errors += 1\n",
    "    return num_errors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def num_decoding_failures(H, logicals, p, num_shots):\n",
    "    matching = Matching.from_check_matrix(H, weights=np.log((1-p)/p), faults_matrix=logicals)\n",
    "    num_errors = 0\n",
    "    for i in range(num_shots):\n",
    "        noise = (np.random.random(H.shape[1]) < p).astype(np.uint8)\n",
    "        syndrome = H@noise % 2\n",
    "        print(\"syndrome = \", syndrome)\n",
    "        \n",
    "        predicted_logicals_flipped = matching.decode(syndrome)\n",
    "        actual_logicals_flipped = logicals@noise % 2\n",
    "        if not np.array_equal(predicted_logicals_flipped, actual_logicals_flipped):\n",
    "            num_errors += 1\n",
    "    return num_errors\n",
    "\n",
    "\n",
    "\n",
    "def num_decoding_failures_vectorised(H, logicals, error_probability, num_shots):\n",
    "    matching = Matching.from_check_matrix(H, weights=np.log((1-p)/p), faults_matrix=logicals)\n",
    "    noise = (np.random.random((num_shots, H.shape[1])) < error_probability).astype(np.uint8)\n",
    "    shots = (noise @ H.T) % 2\n",
    "    actual_observables = (noise @ logicals.T) % 2\n",
    "    predicted_observables = matching.decode_batch(shots)\n",
    "    num_errors = np.sum(np.any(predicted_observables != actual_observables, axis=1))\n",
    "    return num_errors\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72d754e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating L=2...\n",
      "H =  [[1 0 1 0 1 1 0 0]\n",
      " [0 1 0 1 1 1 0 0]\n",
      " [1 0 1 0 0 0 1 1]\n",
      " [0 1 0 1 0 0 1 1]]\n",
      "syndrome =  [0 1 0 1]\n",
      "prediction =  [0 1 0 0 0 0 0 0]\n",
      "syndrome =  [0 0 0 0]\n",
      "prediction =  [0 0 0 0 0 0 0 0]\n",
      "syndrome =  [1 0 1 0]\n",
      "prediction =  [1 0 0 0 0 0 0 0]\n",
      "syndrome =  [0 0 0 0]\n",
      "prediction =  [0 0 0 0 0 0 0 0]\n",
      "syndrome =  [0 0 0 0]\n",
      "prediction =  [0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "num_shots = 5\n",
    "Ls = range(2,4,2)\n",
    "ps = np.linspace(0.1, 0.2, 1)\n",
    "np.random.seed(2)\n",
    "log_errors_all_L = []\n",
    "for L in Ls:\n",
    "    print(\"Simulating L={}...\".format(L))\n",
    "    Hx = toric_code_x_stabilisers(L)\n",
    "    logX = toric_code_x_logicals(L)\n",
    "    log_errors = []\n",
    "    for p in ps:\n",
    "        #num_errors = num_decoding_failures_vectorised(Hx, logX, p, num_shots)\n",
    "        #num_errors = num_decoding_failures(Hx, logX, p, num_shots)\n",
    "        num_errors = num_decoding_failures_via_physical_frame_changes(Hx, logX, p, num_shots)\n",
    "        log_errors.append(num_errors/num_shots)\n",
    "    log_errors_all_L.append(np.array(log_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40959cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (4, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 4)\t1\n"
     ]
    }
   ],
   "source": [
    "A = repetition_code(5)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c35e46da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H =  [[1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1]\n",
      " [0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<9x18 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 36 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toric_code_x_stabilisers(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7583d3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction =  [0 1 0 0 1]\n",
      "[0 0 1 1 0]\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "import pymatching\n",
    "H = csc_matrix([[1, 1, 0, 0, 0],\n",
    "                 [0, 1, 1, 0, 0],\n",
    "                 [0, 0, 1, 1, 0],\n",
    "                 [0, 0, 0, 1, 1]])\n",
    "weights = np.array([1, 1, 1, 1, 1])   # Set arbitrary weights for illustration\n",
    "matching = pymatching.Matching(H, weights=weights)\n",
    "prediction = matching.decode(np.array([1, 1, 0, 1]))\n",
    "print(\"prediction = \", prediction)  # prints: [0 0 1 1 0]\n",
    "# Optionally, we can return the weight as well:\n",
    "prediction, solution_weight = matching.decode(np.array([0, 1, 0, 1]), return_weight=True)\n",
    "print(prediction)  # prints: [0 0 1 1 0]\n",
    "print(solution_weight)  # prints: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c4ccb684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_decoding_failures_noisy_syndromes(H, logicals, p, q, num_shots, repetitions):\n",
    "    matching = Matching(H, weights=np.log((1-p)/p),\n",
    "                repetitions=repetitions, timelike_weights=np.log((1-q)/q))\n",
    "                #repetitions=repetitions, timelike_weights=np.log((1-q)/q), faults_matrix=logicals)\n",
    "    print(\"repetitions = \", repetitions)\n",
    "    num_stabilisers, num_qubits = H.shape\n",
    "    num_errors = 0\n",
    "    for i in range(num_shots):\n",
    "        noise_new = (np.random.rand(num_qubits, repetitions) < p).astype(np.uint8)\n",
    "        noise_cumulative = (np.cumsum(noise_new, 1) % 2).astype(np.uint8)\n",
    "        # When calculating noise_cumulative we sum the errors occuring at a single site over \n",
    "        # different measurement rounds and then we find the modulo 2 of the total error. \n",
    "        print(\"noise_new = \", noise_new)\n",
    "        print(\"noise_cumulative = \", noise_cumulative)\n",
    "        noise_total = noise_cumulative[:,-1]\n",
    "        print(\"noise_total = \", noise_total)\n",
    "        syndrome = H@noise_cumulative % 2\n",
    "        print(\"syndrome = \", syndrome)\n",
    "        #syndrome_error = (np.random.rand(num_stabilisers, repetitions) < q).astype(np.uint8)\n",
    "        syndrome_error = (np.random.rand(num_stabilisers, repetitions) < 0).astype(np.uint8)        \n",
    "        print(\"syndrome_error = \", syndrome_error)\n",
    "        \n",
    "        syndrome_error[:,-1] = 0 # Perfect measurements in last round to ensure even parity\n",
    "        noisy_syndrome = (syndrome + syndrome_error) % 2\n",
    "        # Convert to difference syndrome\n",
    "        noisy_syndrome[:,1:] = (noisy_syndrome[:,1:] - noisy_syndrome[:,0:-1]) % 2\n",
    "        print(\"noisy_syndrome = \", noisy_syndrome)\n",
    "        flipped = matching.decode(noisy_syndrome)\n",
    "        print(\"flipped = \", flipped)\n",
    "        actual_logicals_flipped = noise_total@logicals.T % 2\n",
    "        if not np.array_equal(flipped, actual_logicals_flipped):\n",
    "            num_errors += 1\n",
    "    return num_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3d337d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps= [0.2]\n",
      "Simulating L=2...\n",
      "H =  [[1 0 1 0 1 1 0 0]\n",
      " [0 1 0 1 1 1 0 0]\n",
      " [1 0 1 0 0 0 1 1]\n",
      " [0 1 0 1 0 0 1 1]]\n",
      "repetitions =  3\n",
      "noise_new =  [[0 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [0 0 0]\n",
      " [0 1 1]\n",
      " [0 1 0]]\n",
      "noise_cumulative =  [[0 0 0]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 0]\n",
      " [0 1 1]]\n",
      "noise_total =  [0 1 1 1 0 0 0 1]\n",
      "syndrome =  [[0 1 1]\n",
      " [1 1 0]\n",
      " [1 1 0]\n",
      " [0 1 1]]\n",
      "syndrome_error =  [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "noisy_syndrome =  [[0 1 0]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [0 1 0]]\n",
      "flipped =  [1 0 0 0 0 0 1 0]\n",
      "noise_new =  [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 1]\n",
      " [0 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "noise_cumulative =  [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "noise_total =  [0 0 1 0 1 0 1 1]\n",
      "syndrome =  [[1 0 0]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "syndrome_error =  [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "noisy_syndrome =  [[1 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 0]]\n",
      "flipped =  [1 0 0 0 1 0 0 0]\n",
      "noise_new =  [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]\n",
      " [0 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "noise_cumulative =  [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]\n",
      " [0 1 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "noise_total =  [1 0 1 0 1 0 0 0]\n",
      "syndrome =  [[0 1 1]\n",
      " [0 1 1]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "syndrome_error =  [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "noisy_syndrome =  [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "flipped =  [0 0 0 0 1 0 0 0]\n",
      "noise_new =  [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]\n",
      " [1 0 0]]\n",
      "noise_cumulative =  [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]\n",
      " [1 1 1]]\n",
      "noise_total =  [1 0 1 0 0 1 0 1]\n",
      "syndrome =  [[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]]\n",
      "syndrome_error =  [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "noisy_syndrome =  [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n",
      "flipped =  [1 1 0 0 0 0 0 0]\n",
      "CPU times: user 12.8 ms, sys: 3.68 ms, total: 16.5 ms\n",
      "Wall time: 13.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pymatching import Matching\n",
    "matching=Matching(H)\n",
    "num_shots = 4\n",
    "Ls = range(2,4,2)\n",
    "ps = np.linspace(0.2, 0.4, 1)\n",
    "print(\"ps=\", ps)\n",
    "log_errors_all_L = []\n",
    "for L in Ls:\n",
    "    print(\"Simulating L={}...\".format(L))\n",
    "    Hx = toric_code_x_stabilisers(L)\n",
    "    logX = toric_code_x_logicals(L)\n",
    "    log_errors = []\n",
    "    for p in ps:\n",
    "        nrep = L+1\n",
    "        num_errors = num_decoding_failures_noisy_syndromes(Hx, logX, p, p, num_shots, nrep)\n",
    "        log_errors.append(num_errors/num_shots)\n",
    "    log_errors_all_L.append(np.array(log_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_new =  [[1 0 0]\n",
    " [0 1 0]\n",
    " [0 0 0]\n",
    " [1 1 0]\n",
    " [0 1 1]\n",
    " [0 0 1]\n",
    " [0 0 0]\n",
    " [0 0 0]]\n",
    "\n",
    "noisy_syndrome =  [[1 1 0]\n",
    " [1 1 0]\n",
    " [1 0 0]\n",
    " [1 0 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489e111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
